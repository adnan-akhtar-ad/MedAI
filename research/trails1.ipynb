{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries \n",
    "from langchain_community.document_loaders import PyPDFLoader, DirectoryLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_mistralai import ChatMistralAI \n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Retrieve API keys from environment variables\n",
    "MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ensure API keys are set correctly\n",
    "if not MISTRAL_API_KEY:\n",
    "    raise ValueError(\" MISTRAL_API_KEY is missing. Set it in your .env file.\")\n",
    "\n",
    "if not PINECONE_API_KEY:\n",
    "    raise ValueError(\" PINECONE_API_KEY is missing. Set it in your .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Mistral AI LLM\n",
    "llm = ChatMistralAI(model=\"mistral-medium\", temperature=0.4, max_output_tokens=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract data from PDF\n",
    "def load_pdf_file(data):\n",
    "    loader = DirectoryLoader(data, glob=\"*.pdf\", loader_cls=PyPDFLoader)\n",
    "    documents = loader.load()\n",
    "    return documents\n",
    "\n",
    "extracted_data = load_pdf_file(data='C:/Users/aumpa/OneDrive/Desktop/Projects/Chatbot_Hackthon/Medical_Chatbot/Data/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of text chunks: 7023\n"
     ]
    }
   ],
   "source": [
    "#Split the data into text chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks\n",
    "\n",
    "text_chunks = text_split(extracted_data)\n",
    "print(\"Length of text chunks:\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aumpa\\AppData\\Local\\Temp\\ipykernel_19648\\2664920600.py:6: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  return HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding length: 384\n",
      "Embedding length: 384\n"
     ]
    }
   ],
   "source": [
    "#Download HuggingFace embeddings\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Download HuggingFace embeddings\n",
    "def download_hugging_face_embeddings():\n",
    "    return HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "embeddings = download_hugging_face_embeddings()\n",
    "query_result = embeddings.embed_query(\"Hello World\")\n",
    "print(\"Embedding length:\", len(query_result))\n",
    "\n",
    "def download_hugging_face_embeddings():\n",
    "    return HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "embeddings = download_hugging_face_embeddings()\n",
    "query_result = embeddings.embed_query(\"Hello World\")\n",
    "print(\"Embedding length:\", len(query_result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Pinecone\n",
    "pc = pinecone.Pinecone(api_key=PINECONE_API_KEY)\n",
    "index_name = \"medicalbot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index 'medicalbot' created successfully.\n"
     ]
    }
   ],
   "source": [
    "#Check if the index already exists\n",
    "existing_indexes = [index.name for index in pc.list_indexes()]\n",
    "if index_name not in existing_indexes:\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384,\n",
    "        metric=\"cosine\",\n",
    "        spec=pinecone.ServerlessSpec(cloud=\"aws\", region=\"us-east-1\")\n",
    "    )\n",
    "    print(f\"Index '{index_name}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Index '{index_name}' already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Embed each chunk and upsert embeddings into Pinecone\n",
    "docsearch = PineconeVectorStore.from_documents(\n",
    "    documents=text_chunks,\n",
    "    embedding=embeddings,\n",
    "    index_name=index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load existing Pinecone index\n",
    "docsearch = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")\n",
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define the RAG prompt\n",
    "system_prompt = (\n",
    "    \"You are an assistant for question-answering tasks. \"\n",
    "    \"Use the following pieces of retrieved context to answer \"\n",
    "    \"the question. If you don't know the answer, say that you \"\n",
    "    \"don't know. Use three sentences maximum and keep the \"\n",
    "    \"answer concise.\\n\\n\"\n",
    "    \"{context}\"\n",
    ")\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create RAG chain\n",
    "question_answer_chain = create_stuff_documents_chain(llm, prompt)\n",
    "rag_chain = create_retrieval_chain(retriever, question_answer_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testosterone therapy can help women with low levels of this hormone, but potential side effects include deepening voice, hair growth, and acne. The EROS-CTD is a device approved by the FDA to increase blood flow to the clitoris and improve arousal. Therapy and lifestyle changes, such as quitting smoking and addressing any anxieties or fears about sexual intercourse, can also help resolve sexual dysfunction in women.\n"
     ]
    }
   ],
   "source": [
    "#testing \n",
    "response=rag_chain.invoke({\"input\":\"medicine on sex ?\"})\n",
    "print(response[\"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "# Load API key\n",
    "def load_dotenv():\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    MISTRAL_API_KEY = os.getenv(\"MISTRAL_API_KEY\")\n",
    "\n",
    "from mistral import Mistral\n",
    "\n",
    "def get_mistral_response(user_input):\n",
    "    mistral = Mistral(api_key=os.getenv(\"MISTRAL_API_KEY\"))\n",
    "    response = mistral.chat(\n",
    "        model=\"mistral-7b\",  # Adjust based on your model\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a medical assistant. Format responses in bullet points for clarity. Keep sentences short and informative.\"},\n",
    "            {\"role\": \"user\", \"content\": user_input}\n",
    "        ]\n",
    "    )\n",
    "    return response[\"choices\"][0][\"message\"][\"content\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medibot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
